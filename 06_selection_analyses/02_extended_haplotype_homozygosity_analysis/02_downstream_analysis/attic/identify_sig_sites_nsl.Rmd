---
title: "Bombus population genomics"
output: identify_sig_sites_nsl.html
author: Joe Colgan, Yannick Wurm http://wurmlab.com 
---

## Introduction:  
This script takes the output of selscan as input.  
The input consists of tab-delimited text files, one per bumblebee chromosome, which contains the following information:  
1) Locus ID (chromosome name)
2) Physical position
3) '1' Freq
4) nsl1
5) nsl0
6) Unstandardised nsl
7) Standardised nsl
8) Indicator of 'unsual' or not (1 = unsual; 0 = not)

1. Load libraries:  

```{r, message = FALSE}
# Load libraries; install from scratch if needed
libraries <- c("ggplot2", "ggpubr", "lintr",
               "PopGenome", "zoo", "qqman")
for (lib in libraries) {
    if (require(package = lib, character.only = TRUE)) {
        print("Successful")
    } else {
        print("Installing")
        source("https://bioconductor.org/biocLite.R")
        library(lib, character.only = TRUE )
    }
}

## Create output directory:
dir.create("nsl_significant_sites")
```

2. Read in input:  

```{r, message=FALSE}
## Read in data:
NC_015762.1_nsl_data <- read.table("./input/nsl/NC_015762.1.nsl.out.100bins.norm")
NC_015763.1_nsl_data <- read.table("./input/nsl/NC_015763.1.nsl.out.100bins.norm")
NC_015764.1_nsl_data <- read.table("./input/nsl/NC_015764.1.nsl.out.100bins.norm")
NC_015765.1_nsl_data <- read.table("./input/nsl/NC_015765.1.nsl.out.100bins.norm")
NC_015766.1_nsl_data <- read.table("./input/nsl/NC_015766.1.nsl.out.100bins.norm")
NC_015767.1_nsl_data <- read.table("./input/nsl/NC_015767.1.nsl.out.100bins.norm")
NC_015768.1_nsl_data <- read.table("./input/nsl/NC_015768.1.nsl.out.100bins.norm")
NC_015769.1_nsl_data <- read.table("./input/nsl/NC_015769.1.nsl.out.100bins.norm")
NC_015770.1_nsl_data <- read.table("./input/nsl/NC_015770.1.nsl.out.100bins.norm")
NC_015771.1_nsl_data <- read.table("./input/nsl/NC_015771.1.nsl.out.100bins.norm")
NC_015772.1_nsl_data <- read.table("./input/nsl/NC_015772.1.nsl.out.100bins.norm")
NC_015773.1_nsl_data <- read.table("./input/nsl/NC_015773.1.nsl.out.100bins.norm")
NC_015774.1_nsl_data <- read.table("./input/nsl/NC_015774.1.nsl.out.100bins.norm")
NC_015775.1_nsl_data <- read.table("./input/nsl/NC_015775.1.nsl.out.100bins.norm")
NC_015776.1_nsl_data <- read.table("./input/nsl/NC_015776.1.nsl.out.100bins.norm")
NC_015777.1_nsl_data <- read.table("./input/nsl/NC_015777.1.nsl.out.100bins.norm")
NC_015778.1_nsl_data <- read.table("./input/nsl/NC_015778.1.nsl.out.100bins.norm")
NC_015779.1_nsl_data <- read.table("./input/nsl/NC_015779.1.nsl.out.100bins.norm")
```

3. Create a list:  

```{r, message = FALSE}
## Make a list:
nsl_samples <- list(NC_015762.1_nsl_data = NC_015762.1_nsl_data,
                    NC_015763.1_nsl_data = NC_015763.1_nsl_data,
                    NC_015764.1_nsl_data = NC_015764.1_nsl_data,
                    NC_015765.1_nsl_data = NC_015765.1_nsl_data,
                    NC_015766.1_nsl_data = NC_015766.1_nsl_data,
                    NC_015767.1_nsl_data = NC_015767.1_nsl_data,
                    NC_015768.1_nsl_data = NC_015768.1_nsl_data,
                    NC_015769.1_nsl_data = NC_015769.1_nsl_data,
                    NC_015770.1_nsl_data = NC_015770.1_nsl_data,
                    NC_015771.1_nsl_data = NC_015771.1_nsl_data,
                    NC_015772.1_nsl_data = NC_015772.1_nsl_data,
                    NC_015773.1_nsl_data = NC_015773.1_nsl_data,
                    NC_015774.1_nsl_data = NC_015774.1_nsl_data,
                    NC_015775.1_nsl_data = NC_015775.1_nsl_data,
                    NC_015776.1_nsl_data = NC_015776.1_nsl_data,
                    NC_015777.1_nsl_data = NC_015777.1_nsl_data,
                    NC_015778.1_nsl_data = NC_015778.1_nsl_data,
                    NC_015779.1_nsl_data = NC_015779.1_nsl_data)
```

4. Identify significant peaks:
For the examination of interest peak regions with certain size windows:
The following command will take the absolute nsl values and for nonoverlapping 100kb sites,
calculate the number of SNPs with nsl values with a value higher than 2 (potentially interesting)
divided by the total number of SNPs i.e. get the proportion of interesting SNPs within a particular
region.

```{r, message = FALSE}
## Create an empty dataframe:
df <- data.frame()

## Load quantile value:
load(file = "./results/nsl_quantile.Rdata")

## For each sample in the list:
for (name in nsl_samples){
        ## Examine 100 lines at a time (representative of SNPs),
        ## count the proportion of SNPs with an interesting nsl value.
        name.rolled <- rollapply(abs(name$V7),
                                width = 100,
                                by = 100,
                                function(x) sum(x > nsl_quantile) / 100)
        ## Add the count proportion per window to the empty dataframe:
        df <- c(df, name.rolled)
        ## Unlist the contents of the dataframe:
        df <- unlist(df)
}

## Multiply the contents of the dataframe to get the integer counts of SNPs:
snp_counts <- df * 100
## Combine proportional counts with actual integer counts and store in a dataframe:
unlisted.df <- as.data.frame(cbind(df, snp_counts))

## Perform a binomial probability function test on count data:
unlisted.df$binom_test <- pbinom(q = unlisted.df$snp_counts,
                                 size = 100,
                                 lower.tail = FALSE,
                                 prob = sum(unlisted.df$snp_counts) / (nrow(unlisted.df) * 100))
unlisted.df$binom_test_adjusted <- p.adjust(p = unlisted.df$binom_test,
                                            method = "BH")
## Correct for multiple testing using bonferroni correction:
unlisted.df$binom_test_adjusted <- p.adjust(p = unlisted.df$binom_test,
                                            method = "bonferroni")

## Examine the proportion of SNPs with significance values:
unlisted.df.sig <- unlisted.df[which(unlisted.df$binom_test_adjusted < 0.05), ]
table(unlisted.df.sig$df)
```


```{r, message=FALSE}
## Before examining individual sites:
## Want to plot on a manhattan plot using qqman:
## Loop through the 'zoo' samples:
## Add column containing chromosomal number to each chromosome:
count <- 0
for (item in 1:length(names(nsl_samples))){
        count <- count + 1
        ## Add chromosome number to each individual chromosome:
        nsl_samples[[item]]$chrom <- count
}
```

4. Exploration of a Manhattan plot using qqman:

```{r, message = FALSE}
## Create an empty dataframe:
combined_test <- data.frame()

## For the generation of a manhattan plot:
## Require, "SNP", "CHR", "BP" and "P" columns:
for (item in 1:length(names(nsl_samples))){
        nsl_samples[[item]]$V1 <- sub("^", "rs", nsl_samples[[item]]$V1)
        nsl_samples[[item]] <- nsl_samples[[item]][, c(1, 9, 2, 7)]
        combined_test <- rbind(combined_test,
                               as.data.frame(nsl_samples[[item]]))
}

## Change the column names for plotting:
colnames(combined_test) <- c("SNP", "CHR", "BP", "P")

## Change the 'P' values to absolute values:
combined_test$P <- abs(combined_test$P)

## Plot:
manhattan(combined_test)
```

```{r, message = FALSE}
## Create an empty list:
zoo_samples <- list()

## Transform to zoo format
for (item in 1:length(names(nsl_samples))){
        zoo_samples[[item]] <- zoo((nsl_samples)[[item]])
}

chromosome_names <- names(nsl_samples)
chromosome_names <- gsub("_nsl_data", "", chromosome_names)

## Need to examine sites for each chromosome with a SNP proportion of 0.15:
df_sig <- data.frame()
counts <- data.frame()
output_bed <- data.frame()
chromosome_numbers <- vector()

## Loop through the 'zoo' samples:
for (name in 1:length(zoo_samples)){
                ## 100 consecutive SNPs
                name_rolled <- rollapply(zoo_samples[[name]]$V7,
                                         width = 100,
                                         by = 100,
                                         function(x) sum(x > nsl_quantile) / 100)
                df_sig <- name.rolled[which(name_rolled >= 0.14)]
                df_sig_index <- (index(df_sig))
                df_index <- index(name_rolled)
                chromosome_numbers <- c(chromosome_numbers, rep(chromosome_names[name], length(df_index)))
                print(length(df_index))
                ## For each significant index in turn, do:
                for (i in df_index){
                        ## Add 49 to each index to get the upper limit.
                        df_sig_index_upper <- i + 49
                        ## Add 50 to each index to get the lower limit.
                        df_sig_index_lower <- i - 50
                        name_subset <- zoo_samples[[name]][df_sig_index_lower:df_sig_index_upper]
                        ## Remove line that asks for only special SNPs
                        name_subset_sig <- name_subset[which(name_subset$V8 == 1), ]
                        counts <- c(counts, as.integer(tail(name_subset$V2, n = 1)) -
                                    as.integer(head(name_subset$V2, n = 1)))
                        test <- cbind(as.integer(head(name_subset$V2, n = 1)),
                                      as.integer(tail(name_subset$V2, n = 1)))
                        output_bed <- rbind(output_bed, test)
                }
        }

## Add chromosome names to dataframe:
output_bed$chromosome <- chromosome_numbers

## Check row numbers are the same:
nrow(unlisted.df) == nrow(output_bed)

## Combine genomic coordinates and statistical information:
combined_df <- cbind(output_bed, unlisted.df)

## Reorder columns:
combined_df_rearranged <- combined_df[, c(3, 1, 2, 4, 5, 6, 7)]

colnames(combined_df_rearranged) <- c("Chr",
                                      "Start",
                                      "End",
                                      "SNP_proportion",
                                      "snp_counts",
                                      "binom_test",
                                      "binom_test_adjusted")

## Output file for filtering: 
## Filtering will involve examining the proportion of ambiguous ('N') bases 
## present within genomic windows. Windows with a high proportion (10%) of 
## Ns are to be removed. 
write.table(combined_df_rearranged,
            file = "results/nsl_n41_unfiltered.txt",
            sep = "\t",
            quote = FALSE,
            row.names = FALSE,
            col.names = FALSE)

## Filter significant terms and output:
combined_df_sig <- subset(combined_df_rearranged, binom_test_adjusted < 0.05)

## Write to output:
write.table(combined_df_sig,
            file = "results/nsl_n41_unfiltered.sig.txt",
            sep = "\t",
            quote = FALSE,
            row.names = FALSE,
            col.names = FALSE)

## The region with strongest signature:
head(combined_df_sig[order(-combined_df_sig$SNP_proportion), ])
```

Run lintr:

```{r, message = FALSE}
## Run lintr:
lintr::lint(file = "./identify_sig_sites_nsl.Rmd")
```
